urls_downloaded_cb({"token":"systems","urls":[{"url":"additional/design/draft-metadata.html#unknownunmapped-metadata","node_type":"p","page":"Metadata","sections":["Metadata","Issues","Unknown/Unmapped metadata"],"context":{"gi-language":["default"]}},{"url":"additional/design/encoding.html#terminology","node_type":"ul","page":"Encoding and Muxing","sections":["Encoding and Muxing","Encoding Profile System","Terminology"],"context":{"gi-language":["default"]}},{"url":"additional/design/gstelement.html#gstelement","node_type":"p","page":"GstElement","sections":["GstElement"],"context":{"gi-language":["default"]}},{"url":"additional/design/opengl.html#platform-specifics","node_type":"p","page":"OpenGL","sections":["OpenGL","libgstgl Library","Platform Specifics"],"context":{"gi-language":["default"]}},{"url":"additional/design/stereo-multiview-video.html#encoded-signalling","node_type":"p","page":"Stereoscopic & Multiview Video Handling","sections":["Stereoscopic & Multiview Video Handling","Encoded Signalling"],"context":{"gi-language":["default"]}},{"url":"additional/rtp.html#rtp-and-rtsp-support","node_type":"p","page":"RTP and RTSP support","sections":["RTP and RTSP support"],"context":{"gi-language":["default"]}},{"url":"application-development/advanced/autoplugging.html#autoplugging","node_type":"p","page":"Autoplugging","sections":["Autoplugging"],"context":{"gi-language":["default"]}},{"url":"application-development/appendix/integration.html#integration","node_type":"p","page":"Integration","sections":["Integration"],"context":{"gi-language":["default"]}},{"url":"application-development/appendix/integration.html#linux-and-unixlike-operating-systems","node_type":"h2","page":"Integration","sections":["Integration","Linux and UNIX-like operating systems"],"context":{"gi-language":["default"]}},{"url":"application-development/appendix/quotes.html#quotes-from-the-developers","node_type":"ul","page":"Quotes from the Developers","sections":["Quotes from the Developers"],"context":{"gi-language":["default"]}},{"url":"audio/gstaudiochannels.html#GstAudioChannelPosition","node_type":"p","page":"Audio-channels","sections":["Enumerations"],"context":{"gi-language":["c","javascript","python"]}},{"url":"avtp/index.html#clock-reference-format-crf","node_type":"p","page":"avtp","sections":["avtp","Audio Video Transport Protocol (AVTP) Plugin","Clock Reference Format (CRF)"],"context":{"gi-language":["default"]}},{"url":"curl/curlftpsink.html#curlftpsink:create-tmp-file","node_type":"p","page":"curlftpsink","sections":["Properties"],"context":{"gi-language":["default"]}},{"url":"deploying/mac-osx.html#location-of-dependent-dynamic-libraries","node_type":"p","page":"Mac OS X deployment","sections":["Mac OS X deployment","Relocation of GStreamer in OS X","Location of dependent dynamic libraries."],"context":{"gi-language":["default"]}},{"url":"encoding/encodebin.html#features","node_type":"ul","page":"encodebin","sections":["encodebin","Features"],"context":{"gi-language":["default"]}},{"url":"frequently-asked-questions/dependencies.html#is-gstreamer-x11-independent-can-it-be-used-headless","node_type":"p","page":"Dependencies","sections":["Dependencies","Is GStreamer X11 independent? Can it be used headless?"],"context":{"gi-language":["default"]}},{"url":"frequently-asked-questions/developing.html#how-do-i-compile-programs-that-use-gstreamer","node_type":"p","page":"Developing applications with GStreamer","sections":["Developing applications with GStreamer","How do I compile programs that use GStreamer?"],"context":{"gi-language":["default"]}},{"url":"frequently-asked-questions/general.html#is-gstreamer-available-for-platforms-other-than-linux","node_type":"p","page":"General","sections":["General","Is GStreamer available for platforms other than Linux?"],"context":{"gi-language":["default"]}},{"url":"frequently-asked-questions/mono-repository.html#executive-summary-what-is-all-this-monorepo-talk","node_type":"p","page":"GStreamer mono repository FAQ","sections":["GStreamer mono repository FAQ","Executive Summary: What is all this monorepo talk?"],"context":{"gi-language":["default"]}},{"url":"gst-plugins-bad-codecparsers/gstav1parser.html#GstAV1TransferCharacteristics","node_type":"p","page":"GstAV1Parser","sections":["Enumerations"],"context":{"gi-language":["default"]}},{"url":"gstreamer/gstclock.html#GST_TIME_TO_TIMEVAL","node_type":"p","page":"GstClock","sections":["Function Macros"],"context":{"gi-language":["c"]}},{"url":"gstreamer/gstevent.html#gst_event_new_protection","node_type":"p","page":"GstEvent","sections":["Constructors"],"context":{"gi-language":["c","javascript","python"]}},{"url":"gstreamer/gstplugin.html#gst_plugin_add_dependency","node_type":"p","page":"GstPlugin","sections":["Methods"],"context":{"gi-language":["c","javascript","python"]}},{"url":"gstreamer/gstplugin.html#gst_plugin_add_dependency_simple","node_type":"p","page":"GstPlugin","sections":["Methods"],"context":{"gi-language":["c","javascript","python"]}},{"url":"libav/avmux_mpeg.html#avmux_mpeg-page","node_type":"p","page":"avmux_mpeg","sections":["avmux_mpeg"],"context":{"gi-language":["default"]}},{"url":"libav/avmux_vcd.html#avmux_vcd-page","node_type":"p","page":"avmux_vcd","sections":["avmux_vcd"],"context":{"gi-language":["default"]}},{"url":"libav/index.html#plugin-libav","node_type":"table","page":"FFMPEG plugin","sections":[],"context":{"gi-language":["default"]}},{"url":"mpegts/index.html#atsc-advanced-television-systems-committee","node_type":"h3","page":"MPEG-TS helper library","sections":["MPEG-TS helper library","Specification and References","\nATSC : Advanced Television Systems Committee\n"],"context":{"gi-language":["default"]}},{"url":"mpegts/index.html#dvb-digital-video-broadcasting","node_type":"ul","page":"MPEG-TS helper library","sections":["MPEG-TS helper library","Specification and References","\nDVB : Digital Video Broadcasting\n"],"context":{"gi-language":["default"]}},{"url":"mpegts/index.html#mpegts","node_type":"ul","page":"MPEG-TS helper library","sections":["MPEG-TS helper library","Specification and References","MPEG-TS"],"context":{"gi-language":["default"]}},{"url":"opencv/segmentation.html#segmentation-page","node_type":"p","page":"segmentation","sections":["segmentation"],"context":{"gi-language":["default"]}},{"url":"plugin-development/advanced/allocation.html#memory-allocation","node_type":"p","page":"Memory allocation","sections":["Memory allocation"],"context":{"gi-language":["default"]}},{"url":"plugin-development/advanced/media-types.html#media-types-and-properties","node_type":"p","page":"Media Types and Properties","sections":["Media Types and Properties"],"context":{"gi-language":["default"]}},{"url":"plugin-development/basics/boiler.html#using-the-project-stamp","node_type":"p","page":"Constructing the Boilerplate","sections":["Constructing the Boilerplate","Using the Project Stamp"],"context":{"gi-language":["default"]}},{"url":"plugin-development/element-types/base-classes.html#writing-an-audio-sink","node_type":"p","page":"Pre-made base classes","sections":["Pre-made base classes","Writing a sink","Writing an audio sink"],"context":{"gi-language":["default"]}},{"url":"plugins_doc.html#GStreamer-all-gst-plugins","node_type":"table","page":"Plugins","sections":[],"context":{"gi-language":["default"]}},{"url":"rtp/rtpL8depay.html#rtpL8depay","node_type":"p","page":"rtpL8depay","sections":[],"context":{"gi-language":["default"]}},{"url":"rtp/rtpL8pay.html#rtpL8pay","node_type":"p","page":"rtpL8pay","sections":[],"context":{"gi-language":["default"]}},{"url":"tutorials/basic/dynamic-pipelines.html#introduction","node_type":"p","page":"Basic tutorial 3: Dynamic pipelines","sections":["Basic tutorial 3: Dynamic pipelines","Introduction"],"context":{"gi-language":["default"]}},{"url":"tutorials/playback/digital-audio-pass-through.html#introduction","node_type":"p","page":"Playback tutorial 9: Digital audio pass-through","sections":["Playback tutorial 9: Digital audio pass-through","Introduction"],"context":{"gi-language":["default"]}},{"url":"tutorials/playback/digital-audio-pass-through.html#precautions-with-digital-formats","node_type":"p","page":"Playback tutorial 9: Digital audio pass-through","sections":["Playback tutorial 9: Digital audio pass-through","Precautions with digital formats"],"context":{"gi-language":["default"]}},{"url":"tutorials/playback/hardware-accelerated-video-decoding.html#introduction","node_type":"ul","page":"Playback tutorial 8: Hardware-accelerated video decoding","sections":["Playback tutorial 8: Hardware-accelerated video decoding","Introduction"],"context":{"gi-language":["default"]}},{"url":"video/gstvideooverlay.html#two-basic-usage-scenarios","node_type":"p","page":"GstVideoOverlay","sections":["GstVideoOverlay","Two basic usage scenarios"],"context":{"gi-language":["default"]}},{"url":"video/video-color.html#GstVideoTransferFunction","node_type":"p","page":"video color","sections":["Enumerations"],"context":{"gi-language":["c","javascript","python"]}}]});