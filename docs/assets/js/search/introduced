urls_downloaded_cb({"token":"introduced","urls":[{"url":"additional/design/buffering.html#live-buffering","node_type":"p","page":"Buffering","sections":["Buffering","Some use cases","Live buffering"],"context":{"gi-language":["default"]}},{"url":"additional/design/dmabuf.html#drm-format-caps-field","node_type":"p","page":"DMA buffers","sections":["DMABufs in GStreamer","DRM format caps field"],"context":{"gi-language":["default"]}},{"url":"additional/design/framestep.html#events","node_type":"p","page":"Frame stepping","sections":["Frame stepping","events"],"context":{"gi-language":["default"]}},{"url":"additional/design/latency.html#latency","node_type":"p","page":"Latency","sections":["Latency"],"context":{"gi-language":["default"]}},{"url":"additional/design/query.html#query-types","node_type":"p","page":"Query","sections":["Query","Query types"],"context":{"gi-language":["default"]}},{"url":"application-development/advanced/autoplugging.html#media-types-as-a-way-to-identify-streams","node_type":"p","page":"Autoplugging","sections":["Autoplugging","Media types as a way to identify streams"],"context":{"gi-language":["default"]}},{"url":"application-development/advanced/buffering.html#live-buffering","node_type":"p","page":"Buffering","sections":["Buffering","Live buffering"],"context":{"gi-language":["default"]}},{"url":"application-development/advanced/clocks.html#latency","node_type":"p","page":"Clocks and synchronization in GStreamer","sections":["Clocks and synchronization in GStreamer","Latency"],"context":{"gi-language":["default"]}},{"url":"application-development/basics/elements.html#more-about-element-factories","node_type":"p","page":"Elements","sections":["Elements","More about element factories"],"context":{"gi-language":["default"]}},{"url":"audio/gstaudiobasesink.html#GstAudioBaseSinkDiscontReason","node_type":"p","page":"GstAudioBaseSink","sections":["Enumerations"],"context":{"gi-language":["c","javascript","python"]}},{"url":"audiofx/audiofirfilter.html#audiofirfilter-page","node_type":"p","page":"audiofirfilter","sections":["audiofirfilter"],"context":{"gi-language":["default"]}},{"url":"base/gstbaseparse.html#gst_base_parse_set_latency","node_type":"p","page":"GstBaseParse","sections":["Methods"],"context":{"gi-language":["c","javascript","python"]}},{"url":"base/gstbasesink.html#gst_base_sink_query_latency","node_type":"p","page":"GstBaseSink","sections":["Methods"],"context":{"gi-language":["c","javascript","python"]}},{"url":"debugutilsbad/videocodectestsink.html#videocodectestsink-page","node_type":"p","page":"videocodectestsink","sections":["videocodectestsink"],"context":{"gi-language":["default"]}},{"url":"gstreamer/gstelement.html#gst_element_request_pad_simple","node_type":"p","page":"GstElement","sections":["Methods"],"context":{"gi-language":["c","javascript","python"]}},{"url":"gstreamer/gstpipeline.html#gst_pipeline_set_auto_flush_bus","node_type":"p","page":"GstPipeline","sections":["Methods"],"context":{"gi-language":["c","javascript","python"]}},{"url":"gstreamer/gstquery.html#gst_query_new_latency","node_type":"p","page":"GstQuery","sections":["Constructors"],"context":{"gi-language":["c","javascript","python"]}},{"url":"plugin-development/advanced/interfaces.html#interfaces","node_type":"p","page":"Interfaces","sections":["Interfaces"],"context":{"gi-language":["default"]}},{"url":"plugin-development/advanced/media-types.html#typefind-functions-and-autoplugging","node_type":"p","page":"Media Types and Properties","sections":["Media Types and Properties","Typefind Functions and Autoplugging"],"context":{"gi-language":["default"]}},{"url":"plugin-development/introduction/preface.html#structure-of-this-guide","node_type":"ul","page":"Preface","sections":["Preface","Structure of This Guide"],"context":{"gi-language":["default"]}},{"url":"replaygain/rgvolume.html#rgvolume:headroom","node_type":"p","page":"rgvolume","sections":["Properties"],"context":{"gi-language":["default"]}},{"url":"rtpmanager/rtpbin.html#rtpbin:ts-offset-smoothing-factor","node_type":"p","page":"rtpbin","sections":["Properties"],"context":{"gi-language":["default"]}},{"url":"srtp/srtpenc.html#srtpenc:allow-repeat-tx","node_type":"p","page":"srtpenc","sections":["Properties"],"context":{"gi-language":["default"]}},{"url":"tutorials/android/a-running-pipeline.html#conclusion","node_type":"p","page":"Android tutorial 2: A running pipeline","sections":["Android tutorial 2: A running pipeline","Conclusion"],"context":{"gi-language":["default"]}},{"url":"tutorials/android/media-player.html#supporting-arbitrary-media-uris1","node_type":"p","page":"Android tutorial 4: A basic media player","sections":["Android tutorial 4: A basic media player","A basic media player [C code]","Supporting arbitrary media URIs"],"context":{"gi-language":["default"]}},{"url":"tutorials/index.html#source-code","node_type":"p","page":"Tutorials","sections":["Tutorials","Welcome to the GStreamer Tutorials!","Source code"],"context":{"gi-language":["default"]}},{"url":"tutorials/ios/a-running-pipeline.html#conclusion","node_type":"p","page":"iOS tutorial 2: A running pipeline","sections":["iOS tutorial 2: A running pipeline","Conclusion"],"context":{"gi-language":["default"]}}]});