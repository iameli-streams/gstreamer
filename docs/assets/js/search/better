urls_downloaded_cb({"token":"better","urls":[{"url":"additional/design/adaptive-demuxer.html#adaptive-demuxers-for-dash-hls-and-smooth-streaming","node_type":"p","page":"Adaptive Demuxers for DASH, HLS and Smooth Streaming","sections":["Adaptive Demuxers for DASH, HLS and Smooth Streaming"],"context":{"gi-language":["default"]}},{"url":"additional/design/decodebin.html#gstmultiqueue","node_type":"ul","page":"Decodebin design","sections":["Decodebin design","GstMultiQueue"],"context":{"gi-language":["default"]}},{"url":"additional/design/qos.html#short-term-correction","node_type":"p","page":"Quality-of-Service","sections":["Quality-of-Service","Short term correction"],"context":{"gi-language":["default"]}},{"url":"additional/design/sparsestreams.html#avoiding-processing-silence-from-audio-generators","node_type":"p","page":"Sparse Streams","sections":["Sparse Streams","Use cases","Avoiding processing silence from audio generators"],"context":{"gi-language":["default"]}},{"url":"additional/design/stereo-multiview-video.html#encoded-video-properties-that-need-to-be-encoded-into-caps","node_type":"ul","page":"Stereoscopic & Multiview Video Handling","sections":["Stereoscopic & Multiview Video Handling","Encoded Signalling","Encoded Video: Properties that need to be encoded into caps"],"context":{"gi-language":["default"]}},{"url":"additional/design/stereo-multiview-video.html#output-considerations-with-opengl","node_type":"ul","page":"Stereoscopic & Multiview Video Handling","sections":["Stereoscopic & Multiview Video Handling","Outputting stereo content","Output Considerations with OpenGL"],"context":{"gi-language":["default"]}},{"url":"additional/design/stream-selection.html#gststream-objects","node_type":"p","page":"Stream selection","sections":["Stream selection","GstStream objects"],"context":{"gi-language":["default"]}},{"url":"additional/design/subtitle-overlays.html#background","node_type":"p","page":"Subtitle Overlays and Hardware-Accelerated Playback","sections":["Subtitle Overlays and Hardware-Accelerated Playback","Background"],"context":{"gi-language":["default"]}},{"url":"additional/design/subtitle-overlays.html#the-problem","node_type":"p","page":"Subtitle Overlays and Hardware-Accelerated Playback","sections":["Subtitle Overlays and Hardware-Accelerated Playback","The Problem"],"context":{"gi-language":["default"]}},{"url":"application-development/advanced/pipeline-manipulation.html#manually-adding-or-removing-data-fromto-a-pipeline","node_type":"p","page":"Pipeline manipulation","sections":["Pipeline manipulation","Manually adding or removing data from/to a pipeline"],"context":{"gi-language":["default"]}},{"url":"application-development/advanced/threads.html#when-would-you-want-to-force-a-thread","node_type":"ul","page":"Threads","sections":["Threads","When would you want to force a thread?"],"context":{"gi-language":["default"]}},{"url":"application-development/appendix/integration.html#windows","node_type":"p","page":"Integration","sections":["Integration","Windows"],"context":{"gi-language":["default"]}},{"url":"application-development/appendix/porting.html#list-of-changes","node_type":"ul","page":"Porting 0.8 applications to 0.10","sections":["Porting 0.8 applications to 0.10","List of changes"],"context":{"gi-language":["default"]}},{"url":"application-development/appendix/quotes.html#quotes-from-the-developers","node_type":"ul","page":"Quotes from the Developers","sections":["Quotes from the Developers"],"context":{"gi-language":["default"]}},{"url":"application-development/basics/helloworld.html#conclusion","node_type":"p","page":"Your first application","sections":["Your first application","Conclusion"],"context":{"gi-language":["default"]}},{"url":"audio/audio-quantize.html#gst_audio_quantize_new","node_type":"p","page":"audio quantize","sections":["Functions"],"context":{"gi-language":["c"]}},{"url":"audiofx/audiowsincband.html#audiowsincband-page","node_type":"p","page":"audiowsincband","sections":["audiowsincband"],"context":{"gi-language":["default"]}},{"url":"audiofx/audiowsinclimit.html#audiowsinclimit-page","node_type":"p","page":"audiowsinclimit","sections":["audiowsinclimit"],"context":{"gi-language":["default"]}},{"url":"base/gstqueuearray.html#gst_queue_array_push_sorted","node_type":"p","page":"GstQueueArray","sections":["Methods"],"context":{"gi-language":["c"]}},{"url":"base/gstqueuearray.html#gst_queue_array_push_sorted_struct","node_type":"p","page":"GstQueueArray","sections":["Methods"],"context":{"gi-language":["c"]}},{"url":"check/gstharness.html#gst_harness_add_sink_harness","node_type":"p","page":"GstHarness","sections":["Methods"],"context":{"gi-language":["c","javascript","python"]}},{"url":"codecs/gsth264decoder.html#GstH264DecoderCompliance","node_type":"p","page":"GstH264Decoder","sections":["Enumerations"],"context":{"gi-language":["c","javascript","python"]}},{"url":"contribute/index.html#where-to-file-issues-and-feature-requests","node_type":"ul","page":"Contributing to GStreamer","sections":["Contributing to GStreamer","How to File Issues and Request for Enhancements","Where to File Issues and Feature Requests"],"context":{"gi-language":["default"]}},{"url":"coreelements/multiqueue.html#multiqueue-page","node_type":"ul","page":"multiqueue","sections":["multiqueue"],"context":{"gi-language":["default"]}},{"url":"flac/flacenc.html#flacenc:escape-coding","node_type":"p","page":"flacenc","sections":["Properties"],"context":{"gi-language":["default"]}},{"url":"fluidsynthmidi/index.html#fluiddec-page","node_type":"p","page":"fluiddec","sections":["fluiddec"],"context":{"gi-language":["default"]}},{"url":"frequently-asked-questions/developing.html#what-is-the-coding-style-for-gstreamer-code","node_type":"p","page":"Developing applications with GStreamer","sections":["Developing applications with GStreamer","What is the coding style for GStreamer code?"],"context":{"gi-language":["default"]}},{"url":"gst-editing-services/gesclip.html#ges_clip_split_full","node_type":"p","page":"GESClip","sections":["Methods"],"context":{"gi-language":["c","javascript","python"]}},{"url":"gstreamer/gst.html#gst_segtrap_is_enabled","node_type":"p","page":"GStreamer","sections":["Functions"],"context":{"gi-language":["c","javascript","python"]}},{"url":"gstreamer/gstbus.html#gst_bus_poll","node_type":"p","page":"GstBus","sections":["Methods"],"context":{"gi-language":["c","javascript","python"]}},{"url":"gstreamer/gstelement.html#gst_element_request_pad_simple","node_type":"p","page":"GstElement","sections":["Methods"],"context":{"gi-language":["c","javascript","python"]}},{"url":"gstreamer/gstobject.html#gst_object_get_value_array","node_type":"p","page":"GstObject","sections":["Methods"],"context":{"gi-language":["c"]}},{"url":"gstreamer/gstpipeline.html#GstPipeline","node_type":"p","page":"GstPipeline","sections":[],"context":{"gi-language":["c","javascript","python"]}},{"url":"gstreamer/gsttaglist.html#GST_TAG_GEO_LOCATION_SUBLOCATION","node_type":"p","page":"GstTagList","sections":["Constants"],"context":{"gi-language":["c","javascript","python"]}},{"url":"gstreamer/gstvecdeque.html#gst_vec_deque_push_sorted","node_type":"p","page":"GstVecDeque","sections":["Methods"],"context":{"gi-language":["c"]}},{"url":"gstreamer/gstvecdeque.html#gst_vec_deque_push_sorted_struct","node_type":"p","page":"GstVecDeque","sections":["Methods"],"context":{"gi-language":["c"]}},{"url":"gstreamer/running.html#environment-variables","node_type":"p","page":"Running GStreamer Applications","sections":["Running and debugging GStreamer Applications","Environment variables"],"context":{"gi-language":["default"]}},{"url":"hls/hlssink2.html#hlssink2-page","node_type":"p","page":"hlssink2","sections":["hlssink2"],"context":{"gi-language":["default"]}},{"url":"libav/avenc_cinepak.html#avenc_cinepak:max-extra-cb-iterations","node_type":"p","page":"avenc_cinepak","sections":["Properties"],"context":{"gi-language":["default"]}},{"url":"libav/avenc_cinepak.html#avenc_cinepak:max-strips","node_type":"p","page":"avenc_cinepak","sections":["Properties"],"context":{"gi-language":["default"]}},{"url":"libav/avenc_cinepak.html#avenc_cinepak:strip-number-adaptivity","node_type":"p","page":"avenc_cinepak","sections":["Properties"],"context":{"gi-language":["default"]}},{"url":"plugin-development/advanced/interfaces.html#interfaces","node_type":"p","page":"Interfaces","sections":["Interfaces"],"context":{"gi-language":["default"]}},{"url":"plugin-development/advanced/qos.html#short-term-correction","node_type":"p","page":"Quality Of Service (QoS)","sections":["Quality Of Service (QoS)","Handling QoS","Short term correction"],"context":{"gi-language":["default"]}},{"url":"plugin-development/basics/args.html#adding-properties","node_type":"p","page":"Adding Properties","sections":["Adding Properties"],"context":{"gi-language":["default"]}},{"url":"plugin-development/element-types/base-classes.html#writing-a-source","node_type":"p","page":"Pre-made base classes","sections":["Pre-made base classes","Writing a source"],"context":{"gi-language":["default"]}},{"url":"plugin-development/element-types/one-to-n.html#writing-a-demuxer-or-parser","node_type":"p","page":"Writing a Demuxer or Parser","sections":["Writing a Demuxer or Parser"],"context":{"gi-language":["default"]}},{"url":"tutorials/android/a-running-pipeline.html#conclusion","node_type":"p","page":"Android tutorial 2: A running pipeline","sections":["Android tutorial 2: A running pipeline","Conclusion"],"context":{"gi-language":["default"]}},{"url":"tutorials/android/media-player.html#introduction","node_type":"p","page":"Android tutorial 4: A basic media player","sections":["Android tutorial 4: A basic media player","Introduction"],"context":{"gi-language":["default"]}},{"url":"tutorials/basic/hello-world.html#goal","node_type":"p","page":"Basic tutorial 1: Hello world!","sections":["Basic tutorial 1: Hello world!","Goal"],"context":{"gi-language":["default"]}},{"url":"tutorials/basic/multithreading-and-pad-availability.html#walkthrough","node_type":"p","page":"Basic tutorial 7: Multithreading and Pad Availability","sections":["Basic tutorial 7: Multithreading and Pad Availability","Walkthrough"],"context":{"gi-language":["default"]}},{"url":"tutorials/basic/short-cutting-the-pipeline.html#walkthrough","node_type":"p","page":"Basic tutorial 8: Short-cutting the pipeline","sections":["Basic tutorial 8: Short-cutting the pipeline","Walkthrough"],"context":{"gi-language":["default"]}},{"url":"tutorials/ios/a-basic-media-player.html#introduction","node_type":"p","page":"iOS tutorial 4: A basic media player","sections":["iOS tutorial 4: A basic media player","Introduction"],"context":{"gi-language":["default"]}},{"url":"tutorials/ios/a-running-pipeline.html#conclusion","node_type":"p","page":"iOS tutorial 2: A running pipeline","sections":["iOS tutorial 2: A running pipeline","Conclusion"],"context":{"gi-language":["default"]}},{"url":"va/vah264enc.html#vah264enc:target-usage","node_type":"p","page":"vah264enc","sections":["Properties"],"context":{"gi-language":["default"]}},{"url":"video/gstvideodither.html#gst_video_dither_new","node_type":"p","page":"GstVideoDither","sections":["Functions"],"context":{"gi-language":["c"]}},{"url":"video/gstvideooverlay.html#two-basic-usage-scenarios","node_type":"p","page":"GstVideoOverlay","sections":["GstVideoOverlay","Two basic usage scenarios"],"context":{"gi-language":["default"]}},{"url":"vorbis/vorbisenc.html#vorbisenc:bitrate","node_type":"p","page":"vorbisenc","sections":["Properties"],"context":{"gi-language":["default"]}},{"url":"wavpack/wavpackenc.html#wavpackenc:extra-processing","node_type":"p","page":"wavpackenc","sections":["Properties"],"context":{"gi-language":["default"]}},{"url":"ximagesrc/index.html#ximagesrc:remote","node_type":"p","page":"ximagesrc","sections":["Properties"],"context":{"gi-language":["default"]}},{"url":"xingmux/index.html#xingmux-page","node_type":"p","page":"xingmux","sections":["xingmux"],"context":{"gi-language":["default"]}},{"url":"zbar/index.html#zbar-page","node_type":"ul","page":"zbar","sections":["zbar"],"context":{"gi-language":["default"]}}]});